{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Megaline Plans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The telecommunications company Megaline seeks to optimize its customers' transition to the new \"Smart\" and \"Ultra\" plans, as a significant number of users remain on older plans. The objective of this project is to develop a model that, based on the analysis of customers' monthly usage behavior, can predict which of the two new plans would be most suitable for them. <br><br>\n",
    "\n",
    "To achieve this, a dataset detailing the usage characteristics of subscribers who have already adopted these plans is available. Leveraging this information, a classification model with the highest possible level of accuracy will be built. The minimum performance threshold established for this project is 75% accuracy, which will be evaluated using the provided dataset. Since the data has already been preprocessed, the focus will be directly on developing and validating the predictive model.<br><br>\n",
    "\n",
    "The dataset contains the following information: <br><br>\n",
    "calls — number of calls.<br>\n",
    "minutes — total call duration in minutes.<br>\n",
    "messages — number of text messages.<br>\n",
    "mb_used — Internet traffic used in MB.<br>\n",
    "is_ultra — plan for the current month (Ultra — 1, Smart — 0).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('/Users/pauli/Documents/Data/megaline_plans_ML/users_behavior.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3214 non-null values, of the correct type (all numeric), and no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop a model as accurately as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (1928, 4)\n",
      "Valid set: (643, 4)\n",
      "Test set: (643, 4)\n"
     ]
    }
   ],
   "source": [
    "#Divide the dataset into training and validation sets.\n",
    "\n",
    "features= df.drop(['is_ultra'], axis=1)\n",
    "target= df['is_ultra']\n",
    "\n",
    "# First it is divided into training set (60%) and temporary set (40%)\n",
    "features_train, features_temp, target_train, target_temp = train_test_split(features, target, test_size=0.4, random_state=15)\n",
    "\n",
    "#Then the temporary set is divided into validation (20%) and test (20%)\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_temp, target_temp, test_size=0.5, random_state=15)\n",
    "\n",
    "#Display the size of the sets\n",
    "\n",
    "print(\"Training set:\", features_train.shape)\n",
    "print(\"Valid set:\", features_valid.shape)\n",
    "print(\"Test set:\", features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best depth: 2\n",
      "Best accuracy on validation set: 0.8773989553818332\n",
      "Training set accuracy: 0.8746110765401369\n",
      "Validation set accuracy: 0.6889580093312597\n"
     ]
    }
   ],
   "source": [
    "# Decision tree that has a loop to determine the best depth.\n",
    "\n",
    "best_depth = None\n",
    "best_accuracy = 0\n",
    "\n",
    "for depth in range(1, 51):  # Iterate over 50 depths\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=15)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid)\n",
    "    accuracy = accuracy_score(target_valid, predictions)** 0.5\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_depth = depth\n",
    "        best_accuracy = accuracy\n",
    "        \n",
    "print(f\"Best depth: {best_depth}\")\n",
    "print(f\"Best accuracy on validation set: {best_accuracy}\")\n",
    "\n",
    "# Model accuracy\n",
    "train_predictions = model.predict(features)\n",
    "valid_predictions = model.predict(features_valid)\n",
    "\n",
    "print('Training set accuracy:', accuracy_score(target, train_predictions))\n",
    "print('Validation set accuracy:', accuracy_score(target_valid, valid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is learning the patterns in the training data quite well, with an accuracy of 0.87.\n",
    "On the validation set, the accuracy is below the required threshold of 0.75, suggesting that the model does not generalize sufficiently to new data. <br>\n",
    "Let's test other models to find one that comes closest. <br>The high accuracy on the training set and significantly lower accuracy on the validation set suggests that the model may be overfitting to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a Logistic Regression model, which is a linear algorithm but designed specifically for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.758298755186722\n",
      "Accuracy on validation set: 0.8540453548367299\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=15, max_iter=1000)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "valid_predictions = model.predict(features_valid)\n",
    "valid_accuracy = accuracy_score(target_valid, valid_predictions)**0.5\n",
    "\n",
    "train_predictions = model.predict(features_train)\n",
    "train_accuracy = accuracy_score(target_train, train_predictions)\n",
    "\n",
    "print(f\"Accuracy on training set: {train_accuracy}\")\n",
    "print(f\"Accuracy on validation set: {valid_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model tends to be more robust and less prone to overfitting than a simple decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of estimators (n_estimators): 50\n",
      "Best maximum depth (max_depth): 10\n",
      "Accuracy on the training set: 0.9486286236247387\n",
      "Accuracy on the validation set: 0.8862172569063238\n"
     ]
    }
   ],
   "source": [
    "# Random Forest training with different hyperparameters\n",
    "best_n_estimators = None\n",
    "best_max_depth = None\n",
    "best_accuracy = 0\n",
    "\n",
    "for n_estimators in [50, 100, 150]:  # Iterar sobre diferentes números de arboles\n",
    "    for max_depth in range(5, 26, 5): \n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=15)\n",
    "        model.fit(features_train, target_train)\n",
    "\n",
    "        train_predictions = model.predict(features_train)\n",
    "        train_accuracy = accuracy_score(target_train, train_predictions)** 0.5\n",
    "        valid_predictions = model.predict(features_valid)\n",
    "        valid_accuracy = accuracy_score(target_valid, valid_predictions) ** 0.5\n",
    "        \n",
    "        if valid_accuracy > best_accuracy:\n",
    "            best_n_estimators = n_estimators\n",
    "            best_max_depth = max_depth\n",
    "            best_accuracy = valid_accuracy\n",
    "            best_train_accuracy = train_accuracy\n",
    "    \n",
    "print(f\"Best number of estimators (n_estimators): {best_n_estimators}\")\n",
    "print(f\"Best maximum depth (max_depth): {best_max_depth}\")\n",
    "print(f\"Accuracy on the training set: {best_train_accuracy}\")\n",
    "print(f\"Accuracy on the validation set: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set accuracy is quite close to 1, which means the model is learning the patterns in the training data well. <br>\n",
    "The validation set accuracy is lower than the training set accuracy, but still quite good. <br>The difference between the training (0.95) and validation (0.88) accuracy is moderate, suggesting that the model is well-tuned: there is no obvious overfitting, as the validation accuracy remains high. <br>\n",
    "Although the validation performance is above the 0.75 accuracy threshold set in the project, this indicates that the model is capable of generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous analysis, we concluded that the best model for this case is the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model on the test set is: 0.7884914463452566\n"
     ]
    }
   ],
   "source": [
    "#The model is tested with the characteristics that gave the best RSMD\n",
    "\n",
    "final_model = RandomForestClassifier(random_state=15, n_estimators=50, max_depth=10)\n",
    "final_model.fit(features_train, target_train) \n",
    "\n",
    "predictions = final_model.predict(features_test)\n",
    "score_final = final_model.score(features_test, target_test)\n",
    "print('The accuracy of the model on the test set is:', score_final )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform sanity testing on the selected model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity testing helps confirm that a model is performing reasonably and not simply exploiting accidental patterns or artifacts in the data. <br>\n",
    "In this case, we will evaluate the model by introducing random data. If the accuracy is significantly high, it could indicate a problem with the data or the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy with random labels: 0.47433903576982894\n"
     ]
    }
   ],
   "source": [
    "# Create random labels\n",
    "random_labels = np.random.randint(0, 2, size=target_train.shape)\n",
    "\n",
    "# Train a model with random labels\n",
    "random_forest = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=15)\n",
    "random_forest.fit(features_train, random_labels)\n",
    "\n",
    "\n",
    "random_valid_predictions = random_forest.predict(features_valid)\n",
    "random_valid_accuracy = accuracy_score(target_valid, random_valid_predictions)\n",
    "\n",
    "\n",
    "print(f\"Model accuracy with random labels: {random_valid_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of 48% for accuracy with random labels is very close to 50%, which is exactly what we would expect for a binary classification problem where the predictions are random.<br>This result indicates that the Random Forest model is not learning spurious patterns or artifacts in the data when given random labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we analyzed and developed machine learning models to recommend plans (Smart or Ultra) to Megaline subscribers based on their behavior. <br>\n",
    "\n",
    "We trained three different models using the sklearn library: decision tree, logistic regression, and random forest. These models were evaluated based on their accuracy on the validation set. <br>\n",
    "\n",
    "The best-performing model was the random forest with 50 trees in the set and a maximum depth of 10. It achieved an accuracy of approximately 88% on the validation set and 78% on the test set, passing the given threshold of 75%. It also successfully passed the sanity test. These are the reasons why the company is recommended to use this model to analyze customer behavior and recommend plans. "
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 161,
    "start_time": "2024-12-03T23:09:31.977Z"
   },
   {
    "duration": 311,
    "start_time": "2024-12-03T23:09:50.206Z"
   },
   {
    "duration": 376,
    "start_time": "2024-12-03T23:09:51.533Z"
   },
   {
    "duration": 59,
    "start_time": "2024-12-03T23:10:10.392Z"
   },
   {
    "duration": 21,
    "start_time": "2024-12-03T23:10:31.528Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-03T23:10:53.797Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-03T23:12:20.402Z"
   },
   {
    "duration": 9,
    "start_time": "2024-12-03T23:21:54.486Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-03T23:22:28.764Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-03T23:22:35.419Z"
   },
   {
    "duration": 511,
    "start_time": "2024-12-03T23:46:01.110Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-03T23:50:51.671Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-03T23:56:49.054Z"
   },
   {
    "duration": 30,
    "start_time": "2024-12-03T23:58:09.665Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-04T00:08:40.107Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-04T00:10:41.986Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-04T00:14:34.517Z"
   },
   {
    "duration": 864,
    "start_time": "2024-12-04T00:17:10.754Z"
   },
   {
    "duration": 406,
    "start_time": "2024-12-04T00:18:04.904Z"
   },
   {
    "duration": 54,
    "start_time": "2024-12-04T00:21:49.197Z"
   },
   {
    "duration": 398,
    "start_time": "2024-12-04T00:22:56.553Z"
   },
   {
    "duration": 767,
    "start_time": "2024-12-04T01:10:23.912Z"
   },
   {
    "duration": 217,
    "start_time": "2024-12-04T01:10:28.520Z"
   },
   {
    "duration": 22,
    "start_time": "2024-12-04T01:10:32.157Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-04T01:10:35.823Z"
   },
   {
    "duration": 418,
    "start_time": "2024-12-04T01:10:37.868Z"
   },
   {
    "duration": 420,
    "start_time": "2024-12-04T01:12:42.635Z"
   },
   {
    "duration": 399,
    "start_time": "2024-12-04T01:15:12.113Z"
   },
   {
    "duration": 412,
    "start_time": "2024-12-04T01:18:39.011Z"
   },
   {
    "duration": 421,
    "start_time": "2024-12-04T01:20:43.140Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-04T01:21:20.391Z"
   },
   {
    "duration": 4286,
    "start_time": "2024-12-04T01:26:19.935Z"
   },
   {
    "duration": 4287,
    "start_time": "2024-12-04T01:27:06.476Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-04T01:30:55.112Z"
   },
   {
    "duration": 4205,
    "start_time": "2024-12-04T01:31:02.855Z"
   },
   {
    "duration": 410,
    "start_time": "2024-12-04T01:31:50.216Z"
   },
   {
    "duration": 4225,
    "start_time": "2024-12-04T01:34:38.329Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-04T01:48:24.483Z"
   },
   {
    "duration": 25,
    "start_time": "2024-12-04T01:55:39.977Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-04T02:02:18.556Z"
   },
   {
    "duration": 268,
    "start_time": "2024-12-04T02:03:07.134Z"
   },
   {
    "duration": 268,
    "start_time": "2024-12-04T02:03:40.875Z"
   },
   {
    "duration": 260,
    "start_time": "2024-12-04T02:03:43.601Z"
   },
   {
    "duration": 795,
    "start_time": "2024-12-07T01:07:09.451Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-07T01:07:10.248Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-07T01:07:10.272Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-07T01:07:10.285Z"
   },
   {
    "duration": 408,
    "start_time": "2024-12-07T01:07:10.306Z"
   },
   {
    "duration": 236,
    "start_time": "2024-12-07T01:07:10.716Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-07T01:07:10.954Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-07T01:07:10.955Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-07T01:10:12.395Z"
   },
   {
    "duration": 25,
    "start_time": "2024-12-07T01:10:17.923Z"
   },
   {
    "duration": 4201,
    "start_time": "2024-12-07T01:10:49.841Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-07T01:12:21.473Z"
   },
   {
    "duration": 133,
    "start_time": "2024-12-07T01:12:29.867Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-07T01:28:19.077Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-07T01:28:56.518Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-07T01:29:02.244Z"
   },
   {
    "duration": 129,
    "start_time": "2024-12-07T01:29:06.512Z"
   },
   {
    "duration": 165,
    "start_time": "2024-12-07T02:45:56.972Z"
   }
  ],
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
